{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import timeit\n",
    "import pyarrow.parquet as pq\n",
    "from statistics import median\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID: int64\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "passenger_count: double\n",
       "trip_distance: double\n",
       "RatecodeID: double\n",
       "store_and_fwd_flag: string\n",
       "PULocationID: int64\n",
       "DOLocationID: int64\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "airport_fee: double\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 2492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = pq.read_table('~/Downloads/yellow_tripdata_2022-06.parquet')\n",
    "display(table.schema)\n",
    "meta = pq.read_metadata('~/Downloads/yellow_tripdata_2022-06.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 - In each variable, you will notice that the data is stored as sub-lists. Why are values in each variable stored in sub-lists?\n",
    "* Hint: check the type of each of variable and consult the relevant documentation.\n",
    "    * A: Sublists represent chunk, this way data can be loaded chunkwise with the data being ordered in a way that allows each chunk to be ~maximally compressible \n",
    "* How many sub-lists are there?\n",
    "    * A: 28 sublists\n",
    "* How many elements are in each sublist?\n",
    "    * A: 131072 elemets per sublist, except for the last one (since total number of records is not divisible by 131072)\n",
    "* How many records does the file contain?\n",
    "    * A: 3558124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 3558124\n",
      "Variable: VendorID - 28 sublists, 131072 median elements\n",
      "Variable: tpep_pickup_datetime - 28 sublists, 131072 median elements\n",
      "Variable: tpep_dropoff_datetime - 28 sublists, 131072 median elements\n",
      "Variable: passenger_count - 28 sublists, 131072 median elements\n",
      "Variable: trip_distance - 28 sublists, 131072 median elements\n",
      "Variable: RatecodeID - 28 sublists, 131072 median elements\n",
      "Variable: store_and_fwd_flag - 28 sublists, 131072 median elements\n",
      "Variable: PULocationID - 28 sublists, 131072 median elements\n",
      "Variable: DOLocationID - 28 sublists, 131072 median elements\n",
      "Variable: payment_type - 28 sublists, 131072 median elements\n",
      "Variable: fare_amount - 28 sublists, 131072 median elements\n",
      "Variable: extra - 28 sublists, 131072 median elements\n",
      "Variable: mta_tax - 28 sublists, 131072 median elements\n",
      "Variable: tip_amount - 28 sublists, 131072 median elements\n",
      "Variable: tolls_amount - 28 sublists, 131072 median elements\n",
      "Variable: improvement_surcharge - 28 sublists, 131072 median elements\n",
      "Variable: total_amount - 28 sublists, 131072 median elements\n",
      "Variable: congestion_surcharge - 28 sublists, 131072 median elements\n",
      "Variable: airport_fee - 28 sublists, 131072 median elements\n"
     ]
    }
   ],
   "source": [
    "vnames = table.schema.names\n",
    "print(f'Total number of records: {table.num_rows}')\n",
    "for v in vnames:\n",
    "    print(f'Variable: {v} - {len(table[v].chunks)} sublists, {int(median([len(sublist) for sublist in table[v].chunks]))} median elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: What the time of the first and the last observations?\n",
    "* A: (Based on pickup time, not dropoff) \n",
    "    * First observation is on June 1st, 00:25:41am\n",
    "    * Last observation is on June 30th, 11:33:53pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-01 00:25:41\n",
      "2022-06-30 23:33:53\n"
     ]
    }
   ],
   "source": [
    "print(str(table['tpep_pickup_datetime'][0]))\n",
    "print(str(table['tpep_pickup_datetime'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: What payment types values are there?\n",
    "* A: 0,1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Int64Array object at 0x12f915240>\n",
       "[\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0\n",
       "]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['payment_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Use the following compression schemes to write the table you just read snappy, gzip, brotli, lz4, and gzip\n",
    "* Which compression algorithm provides the smallest file size?\n",
    "    * A: brotli\n",
    "* Which compression algorithm provides the best compression time?\n",
    "    * A: lz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_table(comp):\n",
    "    with io.BytesIO() as f:\n",
    "        pq.write_table(table, f, compression=comp)\n",
    "        print(f'{comp} file size: {(f.getbuffer().nbytes / (1<<20)):.2f} megabytes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snappy file size: 69.64 megabytes.\n",
      "snappy compression time: 0.89 seconds\n",
      "--------------------------------------------------\n",
      "gzip file size: 52.80 megabytes.\n",
      "gzip compression time: 6.06 seconds\n",
      "--------------------------------------------------\n",
      "brotli file size: 50.32 megabytes.\n",
      "brotli compression time: 5.31 seconds\n",
      "--------------------------------------------------\n",
      "lz4 file size: 69.62 megabytes.\n",
      "lz4 compression time: 0.86 seconds\n",
      "--------------------------------------------------\n",
      "gzip file size: 52.80 megabytes.\n",
      "gzip compression time: 6.07 seconds\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for comp in ['snappy', 'gzip', 'brotli', 'lz4', 'gzip']:\n",
    "   test = lambda: compress_table(comp=comp) \n",
    "   print(f'{comp} compression time: {timeit.timeit(test, number=1):.2f} seconds')\n",
    "   print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1edb5cfaac99d768d05c658247d9f0ceef65a79b6bac6a254bb4f37ae7c5b6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
